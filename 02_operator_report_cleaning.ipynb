{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clean Operator Data Reports\n",
    "Code author: Sahar H. El Abbadi\n",
    "Date started: 2022-02-22\n",
    "Date last edited: 2022-03-23\n",
    "\n",
    "### Notes\n",
    "For Carbon Mapper, GHGSat, Kairos, and Methane Air data reports:\n",
    "- This notebook loads the raw excel file submitted by the team. It applies a team-specific function to clean the report. Output is a standardized report that will be used to generate overpass summaries in 03_summarize_results.\n",
    "- All raw report inputs are saved in 00_raw_data. No changes are manually made to operator reports. All cleaning is handled in Python.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from methods_clean_reports import clean_cm, clean_ghgsat, clean_kairos\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean raw data submitted by operators\n",
    "### Notes on formatting:\n",
    "- Operators added their own QC indicators, thus not all columns are uniform across reports\n",
    "- Values left in the Excel file are replaced during import into PyCharm with \"nan\"\n",
    "- Naming convention for dataframes: operator_stage\n",
    "\n",
    "## Notes on Cleaning Operator Data\n",
    "\n",
    "### Generate data frame with the following columns:\n",
    "- Operator: name of operator (Kairos, GHGSat, CarbonMapper, scientificav)\n",
    "- Stage: stage of unblinding (1, 2, or 3)\n",
    "- PerformerExperimentID: Overpass number for a specific operator, incrementing by 1 for each overpass\n",
    "- DateOfSurvey: date in YYYY-MM-DD format\n",
    "- TimestampUTC: timestamp in UTC using 24 hour time\n",
    "- QuantifiedPlume: boolean input, 1 indicates operator submitted a valid quantification estimate for this overpass (excludes quantification estimates that are provided but fail operator QC standards)\n",
    "- FacilityEmissionRate: estimated emissions in kgh\n",
    "- FacilityEmissionRateUpper: upper bound of uncertainty on quantification estimate\n",
    "- FacilityEmissionRateLower: lower bound of uncertainty on quantification estimate\n",
    "- UncertaintyType: type of uncertainty for upper and lower values reported above\n",
    "- OperatorWindspeed: operator reported windspeed in m/s\n",
    "- QCFlag: operator specific QC flag, first digits indicate operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carbon Mapper: Import and Clean Stage 1 and 2 data\n",
    "\n",
    "#### Submission details\n",
    "- Stage 1 submitted on 2023-01-03\n",
    "- Stage 2 submitted on 2023-02-13\n",
    "- Stage 3 submitted 2023-02-28\n",
    "\n",
    "#### QC Indicator:\n",
    "Column: \"Good Quality (Y/N)\"\n",
    "- Y = good quality, quantification included for this stage\n",
    "- N = not good quality, quantification estimate included for potential use in a later stage, but not included in this stage\n",
    "- nan = left blank by Carbon Mapper. All entries that are left blank correspond to overpasses in which CarbonMapper did not observe a released plume. For these cases, \"Quantified\" column reads \"no_detect\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Carbon Mapper Stage 1\n",
    "cm_1_path = pathlib.PurePath('00_raw_reports', 'CM_Stage1_submitted-2023-01-03.xlsx')\n",
    "cm_1 = pd.read_excel(cm_1_path, sheet_name='Survey Summary')\n",
    "\n",
    "# Load Carbon Mapper Stage 2\n",
    "cm_2_path = pathlib.PurePath('00_raw_reports', 'CM_Stage2_submitted-2023-02-13.xlsx')\n",
    "cm_2 = pd.read_excel(cm_2_path, sheet_name='Survey Summary')\n",
    "\n",
    "# Load Carbon Mapper Stage 3\n",
    "cm_3_path = pathlib.PurePath('00_raw_reports', 'CM_Stage3_submitted-2023-02-28.xlsx')\n",
    "cm_3 = pd.read_excel(cm_3_path, sheet_name='Survey Summary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean Carbon Mapper Data\n",
    "\n",
    "#### Required data cleaning:\n",
    "\n",
    "- QuantifiedPlume:\n",
    "    - CarbonMapper reports whether they quantified a plume using two metrics:\n",
    "        - \"CR plume present (Y/N)\" indicates whether they detected a plume. \"N\" indicates that they do not detect a plume, ie they are estimating 0 kgh\n",
    "        - \"Good Quality (Y/N)\" indicates if they quantified the plume observed or not.\n",
    "    - For data cleaning, if \"CR plume present (Y/N)\" == \"Y\" AND \"Good Quality (Y/N)\" == Y, then QuantifiedPlume = 1;\n",
    "    - For now, I will exclude zero values from the quantification plot\n",
    "\n",
    "- TimestampUTC: CarbonMapper reports in local time (UTC - 7), needs to be adjusted to UTC\n",
    "- QCFlag: CarbonMapper only uses on QC indicator (\"Good Quality (Y/N)\"), so I use a QC flag of \"CM-1\" for all items that fail to pass their QC test. For items that pass QC test, I use \"clear\"\n",
    "\n",
    "#### Notes:\n",
    "- For detection capabilities, use \"CR plume present (Y/N)\" column. \"Y\" indicates detection by Carbon Mapper, \"N\" indicates no detection by Carbon Mapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Carbon Mapper data cleaning\n",
    "# Carbon Mapper conducted 121 overpasses\n",
    "total_overpass = 121\n",
    "\n",
    "# Clean Stage 1 data\n",
    "stage = 1\n",
    "cm_1_clean = clean_cm(cm_report=cm_1, cm_overpasses=total_overpass, cm_stage=stage)\n",
    "\n",
    "# Clean Stage 2 data\n",
    "stage = 2\n",
    "cm_2_clean = clean_cm(cm_report=cm_2, cm_overpasses=total_overpass, cm_stage=stage)\n",
    "\n",
    "# Clean stage 3\n",
    "stage = 3\n",
    "cm_3_clean = clean_cm(cm_report=cm_3, cm_overpasses=total_overpass, cm_stage=stage)\n",
    "\n",
    "# Save data\n",
    "cm_1_clean.to_csv(pathlib.PurePath('01_clean_reports', 'cm_1_clean.csv'))\n",
    "cm_2_clean.to_csv(pathlib.PurePath('01_clean_reports', 'cm_2_clean.csv'))\n",
    "cm_3_clean.to_csv(pathlib.PurePath('01_clean_reports', 'cm_3_clean.csv'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GHGSAT Stage 1 and 2 data\n",
    "\n",
    "#### Submission details:\n",
    "- Stage 1 data submitted on 2022-11-21\n",
    "- Stage 2 data submitted on 2022-12-23\n",
    "- Stage 3 data same as Stage 2, submitted 2023-02-17\n",
    "\n",
    "#### QC Indicator:\n",
    "\n",
    "Column: \"QC Flag\"\n",
    "- 1 = Good conditions\n",
    "- 2 = Emissions detected and quantified, but suboptimal conditions may affect SR\n",
    "- 3 = Emissions detected, but not quantified due to suboptimal conditions\n",
    "- 4 = Diffuse emission visible over site (presumably from previous release, due to low wind)\n",
    "- 5 = Discarded (Bad weather/conditions, including clouds, cloud shadow, highly irregular aircraft trajectory, etc.)\n",
    "\n",
    "#### Data processing notes\n",
    "Unable to open the .xlsx file provided by GHGSat in Python, possibly related to read-only restrictions. I have saved the relevant data sheets as csv files to load instead, original submissions by GHGSat are included in 00_raw_data as .xlsx files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# GHGSat Stage 1\n",
    "ghg_1_path = pathlib.PurePath('00_raw_reports', 'GHG_Stage1_submitted-2022-11-21.csv')\n",
    "ghg_1 = pd.read_csv(ghg_1_path)\n",
    "\n",
    "# GHGSat Stage 2\n",
    "ghg_2_path = pathlib.PurePath('00_raw_reports', 'GHG_Stage2_submitted-2022-12-23.csv')\n",
    "ghg_2 = pd.read_csv(ghg_2_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean GHGSat Data\n",
    "\n",
    "#### Required Data Cleaning:\n",
    "- PerformerExperimentID:\n",
    "    - Current ExperimentID is a 54 character string including indicators for date, time, line number and frame. The last entry is an indicator for overpass number that starts at 1 and incrementally increases with each overpass\n",
    "    - Replace this with GH-1, GH-2, etc.\n",
    "- TimestampUTC: GHGSat reports in local time (UTC - 7), needs to be adjusted to UTC\n",
    "- QCFlag: add \"GH-\" prefix to the QC flags used by GHGSat\n",
    "- QuantifiedPlume: if QCFlag (defined below in notes) is 1 or 2, I will consider this a valid and submitted quantification.\n",
    "- UncertaintyType: 1-sigma\n",
    "\n",
    "#### Notes:\n",
    "- QC Flags as defined by GHGSat:\n",
    "    - 1 = \"Good conditions\"\n",
    "    - 2 = \"Emissions detected and quantified, but suboptimal conditions may affect SR\" (what is SR?)\n",
    "    - 3 = \"Emissions detected, but not quantified due to suboptimal conditions\"\n",
    "    - 4 = \"Diffuse emissions visible over site (presumably from previous release, due to low wind)\"\n",
    "    - 5 = \"Discarded (Bad weather/conditions, including clouds, cloud shadow, highly irregular aircraft trajectory, etc.)\"\n",
    "- It looks like in some instances, GHGSat quantified plumes with QC Flag = 4, and in some places they did not. Will need to look into this more rigorously\n",
    "- QuantifiedPlume: compare QCFlags 1 and 2 for any significant difference in error estimation\n",
    "- Manually correct incorrect timestamp for Overpass ID #75: per email correspondance with Marianne Girard adn March 22, 2023 the timestamp should be 2022-11-02 16:58:28 UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHGSat Data Cleaning\n",
    "\n",
    "# GHGSat conducted 192 overpasses\n",
    "ghg_overpass = 192\n",
    "\n",
    "# Import Stage 1 data\n",
    "ghg_stage = 1\n",
    "ghg_1_clean = clean_ghgsat(ghg_report=ghg_1, ghg_overpasses=ghg_overpass, ghg_stage=ghg_stage)\n",
    "\n",
    "# Import Stage 2 data\n",
    "ghg_stage = 2\n",
    "ghg_2_clean = clean_ghgsat(ghg_report=ghg_2, ghg_overpasses=ghg_overpass, ghg_stage=ghg_stage)\n",
    "\n",
    "# Save data\n",
    "ghg_1_clean.to_csv(pathlib.PurePath('01_clean_reports', 'ghg_1_clean.csv'))\n",
    "ghg_2_clean.to_csv(pathlib.PurePath('01_clean_reports', 'ghg_2_clean.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kairos Stage data: individual pods (LS23 and LS25)\n",
    "\n",
    "#### Submission details\n",
    "- Stage 1 submitted on 2022-11-17\n",
    "- Stage 2 submitted on 2022-12-20\n",
    "- Stage 3 submitted on 2023-02-23\n",
    "- Kairos submitted data for two pods, LS23 and LS25. They analyzed the data independently, but did not report this until after testing was complete.\n",
    "\n",
    "#### QC Indicator:\n",
    "(I ran the UNIQUE function in Excel to identify values in their original report)\n",
    "- \"Plane deviated from flightline\"\n",
    "- \"PARTIAL DETECTION\"\n",
    "- \"Cutoff - low confidence quantification\"\n",
    "- \"Excessive methane pooling near site\"\n",
    "- \"Excessive methane pooling over site\" (appears twice - possible extra space at end?)\n",
    "- \"Plane deviation from flightpath\"\n",
    "- \"Glare\"\n",
    "\n",
    "#### Data processing notes\n",
    "Unable to open the .xlsx file provided by GHGSat in Python, possibly related to read-only restrictions. I have saved the relevant data sheets as csv files to load instead, original submissions by GHGSat are included in 00_raw_data as .xlsx files.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Kairos Stage 1\n",
    "kairos_ls23_1_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage1_podLS23_submitted-2022-11-17.csv')\n",
    "kairos_ls25_1_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage1_podLS25_submitted-2022-11-17.csv')\n",
    "kairos_ls23_1 = pd.read_csv(kairos_ls23_1_path)\n",
    "kairos_ls25_1 = pd.read_csv(kairos_ls25_1_path)\n",
    "\n",
    "# Kairos Stage 2\n",
    "kairos_ls23_2_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage2_podLS23_submitted-2022-12-20.csv')\n",
    "kairos_ls25_2_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage2_podLS25_submitted-2022-12-20.csv')\n",
    "kairos_ls23_2 = pd.read_csv(kairos_ls23_2_path)\n",
    "kairos_ls25_2 = pd.read_csv(kairos_ls25_2_path)\n",
    "\n",
    "# Kairos Stage 3\n",
    "kairos_ls23_3_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage3_podLS23_submitted-2023-02-23.csv')\n",
    "kairos_ls25_3_path = pathlib.PurePath('00_raw_reports', 'Kairos_Stage3_podLS25_submitted-2023-02-23.csv')\n",
    "kairos_ls23_3 = pd.read_csv(kairos_ls23_3_path)\n",
    "kairos_ls25_3 = pd.read_csv(kairos_ls25_3_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean Kairos Data: reports for individual pods\n",
    "\n",
    "#### Required Data Cleaning:\n",
    "QC Flag:\n",
    "- Kairos uses the following QC flags in their column \"Kairos Flag for Dropped Passes or Uncertain Rate Quantification\":\n",
    "    - \"Plane deviated from flightline\"\n",
    "    - \"PARTIAL DETECTION\"\n",
    "    - \"Cutoff - low confidence quantification\"\n",
    "    - \"Excessive methane pooling near site\"\n",
    "    - \"Excessive methane pooling over site\" (appears twice - possible extra space at end?)\n",
    "    - \"Plane deviation from flightpath\"\n",
    "    - \"Glare\"\n",
    "- Kairos reported for pods LS23 and LS25\n",
    "\n",
    "#### Notes:\n",
    "- First, clean reports for each pod as reported by Kairos.\n",
    "- Next, generate a combined Kairos clean dataframe with FacilityEmissionRate equal to the average of the FacilityEmissionRate reported by both LS23 and LS25. The individual LS23 and LS25 values will be the upper and lower uncertainty\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Kairos Data Cleaning of LS23 and LS25 reports\n",
    "\n",
    "# Kairos conducted 349 overpasses\n",
    "kairos_overpass = 349\n",
    "\n",
    "# Stage 1, pods LS23 and LS25\n",
    "kairos_stage = 1\n",
    "kairos_1_ls23_clean = clean_kairos(kairos_report=kairos_ls23_1, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "kairos_1_ls25_clean = clean_kairos(kairos_report=kairos_ls25_1, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "\n",
    "# Stage 2, pods LS23 and LS25\n",
    "kairos_stage = 2\n",
    "kairos_2_ls23_clean = clean_kairos(kairos_report=kairos_ls23_2, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "kairos_2_ls25_clean = clean_kairos(kairos_report=kairos_ls25_2, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "\n",
    "# Stage 3, pods LS23 and LS25\n",
    "kairos_stage = 3\n",
    "kairos_3_ls23_clean = clean_kairos(kairos_report=kairos_ls23_3, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "kairos_3_ls25_clean = clean_kairos(kairos_report=kairos_ls25_3, kairos_overpasses=kairos_overpass, kairos_stage=kairos_stage)\n",
    "\n",
    "# Save Data\n",
    "kairos_1_ls23_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_1_ls23_clean.csv'))\n",
    "kairos_1_ls25_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_1_ls25_clean.csv'))\n",
    "kairos_2_ls23_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_2_ls23_clean.csv'))\n",
    "kairos_2_ls25_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_2_ls25_clean.csv'))\n",
    "kairos_3_ls23_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_3_ls23_clean.csv'))\n",
    "kairos_3_ls25_clean.to_csv(pathlib.PurePath('01_clean_reports', 'kairos_3_ls25_clean.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate combined notebook\n",
    "- Because Kairos reported results as individual pods, we combine these results in the main manuscript. This script generates the combined clean report.\n",
    "- Combined report averages the values found by both pods for FacilityEmissionRate\n",
    "- FacilityEmissionRateUpper and FacilityEmissionRateLower are set to the individual values of the pods themselves\n",
    "- If one pod detects a release and the other does not, we use the value of the pod that detected the release\n",
    "- Similarly, if one pod experiences a QC issue but the other does not, we use the value by the pod that reports values (ie did not have a QC problem)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "from methods_clean_reports import make_kairos_combo\n",
    "\n",
    "kairos_overpass = 349\n",
    "kairos_stage = 1\n",
    "kairos_1_clean = make_kairos_combo(kairos_overpass, kairos_stage)\n",
    "\n",
    "kairos_stage = 2\n",
    "kairos_2_clean = make_kairos_combo(kairos_overpass, kairos_stage)\n",
    "\n",
    "kairos_stage = 3\n",
    "kairos_3_clean = make_kairos_combo(kairos_overpass, kairos_stage)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scientific Aviation Data\n",
    "\n",
    "#### Submission details\n",
    "- Only submitted Phase I estimates\n",
    "- Submitted on 2023-01-21\n",
    "\n",
    "#### QC Indicator\n",
    "Initial Spreadsheet reports quantification estimates for all releases, and indicates if release does not meet Scientific Aviation criteria by printing the text in grey. All greyed out releases include a comment explaining why the measurement was not valid\n",
    "\n",
    "- Entries in the \"Comments\" column:\n",
    "- \"*not enough of plumes captured at low end due to restrictions in altitude (powerlines)\"\n",
    "- \"* same as above\" (referring to powerline problem)\n",
    "- \"*too few laps\"\n",
    "- \"*too few laps; upwind interference from landfill\"\n",
    "- \"*not enough of plume captured near surface\"\n",
    "\n",
    "#### Generating clean report\n",
    "Scientific Aviation did not submit a report using the Stanford provided template. Because formatting of the excel file is not readily machine-readable, Sahar El Abbadi manual generated the clean version of the data. Because Scientific Aviation uses a different measurement approach, the following columns are used in generating the clean dataframe:\n",
    "- Operator\n",
    "- Stage\n",
    "- overpass_id\n",
    "- DateOfSurvey\n",
    "- StartUTC\n",
    "- EndUTC\n",
    "- Detected\n",
    "- QuantifiedPlume\n",
    "- FacilityEmissionRate\n",
    "- FacilityEmissionRateUpper\n",
    "- FacilityEmissionRateLower\n",
    "- UncertaintyType\n",
    "- OperatorWindspeed\n",
    "- QCFlag\n",
    "- OperatorKeep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Scientific Aviation data import - this was generated manually by Sahar because SciAV did not submit using report template\n",
    "\n",
    "sciav_path = pathlib.PurePath('00_raw_reports', 'SciAv_Stage1_submitted-2023-02-21.xlsx')\n",
    "sciav_1 = pd.read_excel(sciav_path)\n",
    "\n",
    "sciav_clean_path = pathlib.PurePath('01_clean_reports', 'sciav_1_clean.csv')\n",
    "sciav_1_clean = pd.read_csv(sciav_clean_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methane Air data cleaning\n",
    "\n",
    "Notes :\n",
    "- MAIR submitted an extra column with plume area, column title is PlumeLength(m)(Area)^.5\n",
    "- Uncertainty type: they report 95% confidence interval and \"MINIMUM\" -> need to ask for clarification on this\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Methane Air data report\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from methods_clean_reports import clean_mair\n",
    "\n",
    "# load raw file\n",
    "mair_path = pathlib.PurePath('00_raw_reports', 'MAIR_Stage1_submitted_2023-03-22.csv')\n",
    "mair_1 = pd.read_csv(mair_path)\n",
    "\n",
    "mair_report = mair_1\n",
    "mair_overpasses = 24\n",
    "mair_stage = 1\n",
    "mair_1_clean = clean_mair(mair_report, mair_overpasses, mair_stage)\n",
    "\n",
    "# Save Data\n",
    "mair_1_clean.to_csv(pathlib.PurePath('01_clean_reports', 'mair_1_clean.csv'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Methane Air individual results report\n",
    "Methane Air submitted a report which averaged their two approaches:  mIME and DI methods. On March 31st, they submitted results for each individual method.\n",
    "\n",
    "They did not use the data reporting template, make and save a copy here using their submission on 2023-03-22"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# load raw file from 03/22/2023\n",
    "mair_path = pathlib.PurePath('00_raw_reports', 'MAIR_Stage1_submitted_2023-03-22.csv')\n",
    "mair_raw = pd.read_csv(mair_path)\n",
    "\n",
    "# load mIME results from csv file\n",
    "mair_path_raw = pathlib.PurePath('00_raw_reports', 'MAIR_2023-03-31_SubmissionDocs', 'outputs_and_raw_mIME_DI_20230327.csv')\n",
    "\n",
    "# make mIME method\n",
    "mair_raw_df = pd.read_csv(mair_path_raw)\n",
    "mair_mIME = mair_raw.copy()\n",
    "mair_mIME['FacilityEmissionRate'] = mair_raw_df['mIME_flux_kg.hr']\n",
    "mair_mIME['FacilityEmissionRateUpper'] = mair_raw_df['mIME_upper']\n",
    "mair_mIME['FacilityEmissionRateLower'] = mair_raw_df['mIME_lower']\n",
    "\n",
    "# make DI method\n",
    "mair_DI = mair_raw.copy()\n",
    "mair_DI['FacilityEmissionRate'] = mair_raw_df['DI_flux_kg.hr']\n",
    "mair_DI['FacilityEmissionRateUpper'] = mair_raw_df['DI_upper']\n",
    "mair_DI['FacilityEmissionRateLower'] = mair_raw_df['DI_lower']\n",
    "\n",
    "\n",
    "mair_mIME_1_clean = clean_mair(mair_report=mair_mIME, mair_overpasses=24, mair_stage=1)\n",
    "mair_DI_1_clean = clean_mair(mair_report=mair_DI, mair_overpasses=24, mair_stage=1)\n",
    "\n",
    "mair_mIME_1_clean.to_csv(pathlib.PurePath('01_clean_reports', 'mair_mIME_1_clean.csv'))\n",
    "mair_DI_1_clean.to_csv(pathlib.PurePath('01_clean_reports', 'mair_DI_1_clean.csv'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

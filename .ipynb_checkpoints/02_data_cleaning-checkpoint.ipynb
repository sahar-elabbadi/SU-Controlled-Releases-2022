{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from data_methods import convert_utc, convert_to_twentyfour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data submitted by operators\n",
    "### Notes on formatting:\n",
    "- Operators added their own QC indicators, thus not all columns are uniform across reports\n",
    "- Values left in the Excel file are replaced during import into PyCharm with \"nan\"\n",
    "- Naming convention for dataframes: operator_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carbon Mapper Stage 1 and 2 data\n",
    "\n",
    "#### Submission details\n",
    "- Stage 1 submitted on 2023-01-03\n",
    "- Stage 2 submitted on 2023-02-13\n",
    "\n",
    "#### QC Indicator:\n",
    "Column: \"Good Quality (Y/N)\"\n",
    "- Y = good quality, quantification included for this stage\n",
    "- N = not good quality, quantification estimate included for potential use in a later stage, but not included in this stage\n",
    "- nan = left blank by Carbon Mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon Mapper Stage 1\n",
    "cm_1_path = pathlib.PurePath('00_raw_data', 'CM_Stage1_submitted-2023-01-03.xlsx')\n",
    "cm_1 = pd.read_excel(cm_1_path, sheet_name='Survey Summary')\n",
    "\n",
    "# Carbon Mapper Stage 2\n",
    "cm_2_path = pathlib.PurePath('00_raw_data', 'CM_Stage2_submitted-2023-02-13.xlsx')\n",
    "cm_2 = pd.read_excel(cm_1_path, sheet_name='Survey Summary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GHGSAT Stage 1 and 2 data\n",
    "\n",
    "#### Submission details:\n",
    "- Stage 1 data submitted on 2022-11-21\n",
    "- Stage 2 data submitted on 2022-12-23\n",
    "- Stage 3 data same as Stage 2, submitted 2023-02-17\n",
    "\n",
    "#### QC Indicator:\n",
    "\n",
    "Column: \"QC Flag\"\n",
    "- 1 = Good conditions\n",
    "- 2 = Emissions detected and quantified, but suboptimal conditions may affect SR\n",
    "- 3 = Emissions detected, but not quantified due to suboptimal conditions\n",
    "- 4 = Diffuse emission visible over site (presumably from previous release, due to low wind)\n",
    "- 5 = Discarded (Bad weather/conditions, including clouds, cloud shadow, highly irregular aircraft trajectory, etc.)\n",
    "\n",
    "#### Data processing notes\n",
    "Unable to open the .xlsx file provided by GHGSat in Python, possibly related to read-only restrictions. I have saved the relevant data sheets as csv files to load instead, original submissions by GHGSat are included in 00_raw_data as .xlsx files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHGSat Stage 1\n",
    "ghg_1_path = pathlib.PurePath('00_raw_data', 'GHG_Stage1_submitted-2022-11-21.csv')\n",
    "ghg_1 = pd.read_csv(ghg_1_path)\n",
    "\n",
    "# GHGSat Stage 2\n",
    "ghg_2_path = pathlib.PurePath('00_raw_data', 'GHG_Stage2_submitted-2022-12-23.csv')\n",
    "ghg_2 = pd.read_csv(ghg_2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kairos Stage 1 and 2 data\n",
    "\n",
    "#### Submission details\n",
    "- Stage 1 submitted on 2022-11-17\n",
    "- Stage 2 submitted on 2022-12-20\n",
    "- Kairos submitted data for two pods, LS23 and LS25. They analyzed the data independently, but did not report this until after testing was complete.\n",
    "\n",
    "#### QC Indicator:\n",
    "(I ran the UNIQUE function in Excel to identify values in their original report)\n",
    "- \"Plane deviated from flightline\"\n",
    "- \"PARTIAL DETECTION\"\n",
    "- \"Cutoff - low confidence quantification\"\n",
    "- \"Excessive methane pooling near site\"\n",
    "- \"Excessive methane pooling over site\" (appears twice - possible extra space at end?)\n",
    "- \"Plane deviation from flightpath\"\n",
    "- \"Glare\"\n",
    "\n",
    "#### Data processing notes\n",
    "Unable to open the .xlsx file provided by GHGSat in Python, possibly related to read-only restrictions. I have saved the relevant data sheets as csv files to load instead, original submissions by GHGSat are included in 00_raw_data as .xlsx files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kairos Stage 1\n",
    "kairos_ls23_1_path = pathlib.PurePath('00_raw_data', 'Kairos_Stage1_podLS23_submitted-2022-11-17.csv')\n",
    "kairos_ls25_1_path = pathlib.PurePath('00_raw_data', 'Kairos_Stage1_podLS25_submitted-2022-11-17.csv')\n",
    "\n",
    "kairos_ls23_1 = pd.read_csv(kairos_ls23_1_path)\n",
    "kairos_ls25_1 = pd.read_csv(kairos_ls25_1_path)\n",
    "\n",
    "# GHGSat Stage 2\n",
    "kairos_ls23_2_path = pathlib.PurePath('00_raw_data', 'Kairos_Stage2_podLS25_submitted-2022-12-20.csv')\n",
    "kairos_ls25_2_path = pathlib.PurePath('00_raw_data', 'Kairos_Stage2_podLS25_submitted-2022-12-20.csv')\n",
    "kairos_ls23_2 = pd.read_csv(kairos_ls23_2_path)\n",
    "kairos_ls25_2 = pd.read_csv(kairos_ls25_2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific Aviation Data\n",
    "\n",
    "#### Submission details\n",
    "- Only submitted Phase I estimates\n",
    "- Submitted on 2023-01-21\n",
    "\n",
    "#### QC Indicator\n",
    "Initial Spreadsheet reports quantification estimates for all releases, and indicates if release does not meet Scientific Aviation criteria by printing the text in grey. All greyed out releases include a comment explaining why the measurement was not valid\n",
    "\n",
    "- Entries in the \"Comments\" column:\n",
    "- \"*not enough of plumes captured at low end due to restrictions in altitude (powerlines)\"\n",
    "- \"* same as above\" (referring to powerline problem)\n",
    "- \"*too few laps\"\n",
    "- \"*too few laps; upwind interference from landfill\"\n",
    "- \"*not enough of plume captured near surface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific Aviation data import\n",
    "\n",
    "sciav_path = pathlib.PurePath('00_raw_data', 'SciAv_Stage1_submitted-2023-02-21.xlsx')\n",
    "sciav_1 = pd.read_excel(sciav_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Operator Data\n",
    "\n",
    "### Generate data frame with the following columns:\n",
    "- Operator: name of operator (kairos, ghgsat, carbonmapper, scientificav)\n",
    "- Stage: stage of unblinding (1, 2, or 3)\n",
    "- PerformerExperimentID: Unique alphanumeric ID for each overpass. First two letters indicate the operator being tested (CM = Carbon Mapper, GH = GHGSat, KA = Kairos, SC = SciAv), followed by the overpass number. Overpass number starts at 1 and increments by 1 for each overpass. For example:\n",
    "    - CM-001 means Carbon Mapper - first overpass\n",
    "    - KA-34 means Kairos - 34th overpass\n",
    "- DateOfSurvey: date in YYYY-MM-DD format\n",
    "- TimestampUTC: timestamp in UTC using 24 hour time\n",
    "- QuantifiedPlume: boolean input, 1 indicates operator submitted a valid quantification estimate for this overpass (excludes quantification estimates that are provided but fail operator QC standards)\n",
    "- FacilityEmissionRate: estimated emissions in kgh\n",
    "- FacilityEmissionRateUpper: upper bound of uncertainty on quantification estimate\n",
    "- FacilityEmissionRateLower: lower bound of uncertainty on quantification estimate\n",
    "- UncertaintyType: type of uncertainty for upper and lower values reported above\n",
    "- OperatorWindspeed: operator reported windspeed in m/s\n",
    "- QCFlag: operator specific QC flag, first digits indicate operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array with column names for clean data\n",
    "\n",
    "report_col = ['Operator',\n",
    "              'Stage',\n",
    "              'PerformerExperimentID',\n",
    "              'DateOfSurvey',\n",
    "              'TimestampUTC',\n",
    "              'QuantifiedPlume',\n",
    "              'FacilityEmissionRate',\n",
    "              'FacilityEmissionRateUpper',\n",
    "              'FacilityEmissionRateLower',\n",
    "              'UncertaintyType',\n",
    "              'OperatorWindspeed',\n",
    "              'QCFlag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Carbon Mapper Data\n",
    "\n",
    "#### Required data cleaning:\n",
    "\n",
    "- QuantifiedPlume:\n",
    "    - CarbonMapper reports whether they quantified a plume using two metrics:\n",
    "        - \"CR plume present (Y/N)\" indicates whether they detected a plume. \"N\" indicates that they do not detect a plume, ie they are estimating 0 kgh\n",
    "        - \"Good Quality (Y/N)\" indicates if they quantified the plume observed or not.\n",
    "    - For data cleaning, if \"CR plume present (Y/N)\" == \"Y\" AND \"Good Quality (Y/N)\" == Y, then QuantifiedPlume = 1;\n",
    "    - For now, I will exclude zero values from the quantification plot\n",
    "\n",
    "- TimestampUTC: CarbonMapper reports in local time (UTC - 7), needs to be adjusted to UTC\n",
    "- QCFlag: CarbonMapper only uses on QC indicator (\"Good Quality (Y/N)\"), so I use a QC flag of \"CM-1\" for all items that fail to pass their QC test. For items that pass QC test, I use \"clear\"\n",
    "\n",
    "#### Notes:\n",
    "- For detection capabilities, use \"CR plume present (Y/N)\" column. \"Y\" indicates detection by Carbon Mapper, \"N\" indicates no detection by Carbon Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Carbon Mapper data cleaning\n",
    "\n",
    "# Carbon Mapper conducted 121 overpasses\n",
    "total_overpass = 121\n",
    "# Set Stage for data analysis (1, 2 or 3)\n",
    "cm_stage = 1\n",
    "\n",
    "cm_overpasses = np.linspace(1, total_overpass, total_overpass) # for indexing for loop\n",
    "overpass_list = [] # for generating all new rows\n",
    "\n",
    "for overpass in cm_overpasses:\n",
    "\n",
    "    # Check if the quantification estimate is valid by passing Carbon Mapper's \"Good Quality\" criteria. Use quantification estimates if valid, otherwise input nan\n",
    "    if cm_1.loc[overpass-1, \"CR plume present (Y/N)\"] == \"Y\" and cm_1.loc[overpass-1, \"Good Quality (Y/N)\"] == \"Y\":\n",
    "        quantified = 1\n",
    "        emission_rate = cm_1.loc[overpass-1, \"Emission Rate (kg/hr)\"]\n",
    "        emission_upper = cm_1.loc[overpass-1, \"FacilityEmissionRateUpper\"]\n",
    "        emission_lower = cm_1.loc[overpass-1, \"FacilityEmissionRateLower\"]\n",
    "    else:\n",
    "        quantified = 0\n",
    "        emission_rate = float(\"nan\")\n",
    "        emission_upper = float(\"nan\")\n",
    "        emission_lower = float(\"nan\")\n",
    "\n",
    "    # If the overpass does not pass Carbon Mapper's criteria,\n",
    "    if cm_1.loc[overpass-1, \"Good Quality (Y/N)\"] == \"N\":\n",
    "        qc_flag = 'CM-1'\n",
    "    else:\n",
    "        qc_flag = 'clear' # for now, use flag \"clear\" to indicate if the overpass passes all operator QC\n",
    "\n",
    "    # Convert local time to UTC\n",
    "    local_time = cm_1.loc[overpass-1, \"Timestamp (hyperspectral technologies only)\"]\n",
    "    utc_time = convert_utc(local_time, 7)\n",
    "\n",
    "    new_row = {\n",
    "            'Operator': 'CarbonMapper',\n",
    "            'Stage': cm_stage,\n",
    "            'PerformerExperimentID': f'CM-{overpass:1.0f}',\n",
    "            'DateOfSurvey': cm_1.loc[overpass-1, \"DateOfSurvey\"].strftime('%Y-%m-%d'),\n",
    "            'TimestampUTC': utc_time,\n",
    "            'QuantifiedPlume': quantified,\n",
    "            'FacilityEmissionRate': emission_rate,\n",
    "            'FacilityEmissionRateUpper': emission_upper,\n",
    "            'FacilityEmissionRateLower': emission_lower,\n",
    "            'UncertaintyType': '1-sigma',\n",
    "            'OperatorWindspeed': cm_1.loc[overpass-1, \"WindSpeed (m/s)\"],\n",
    "            'QCFlag': qc_flag,\n",
    "    }\n",
    "    overpass_list.append(new_row)\n",
    "\n",
    "cm_clean = pd.DataFrame(overpass_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean GHGSat Data\n",
    "\n",
    "#### Required Data Cleaning:\n",
    "- PerformerExperimentID:\n",
    "    - Current ExperimentID is a 54 character string including indicators for date, time, line number and frame. The last entry is an indicator for overpass number that starts at 1 and incrementally increases with each overpass\n",
    "    - Replace this with GH-1, GH-2, etc.\n",
    "- TimestampUTC: GHGSat reports in local time (UTC - 7), needs to be adjusted to UTC\n",
    "- QCFlag: add \"GH-\" prefix to the QC flags used by GHGSat\n",
    "- QuantifiedPlume: if QCFlag (defined below in notes) is 1 or 2, I will consider this a valid and submitted quantification.\n",
    "- UncertaintyType: 1-sigma\n",
    "\n",
    "#### Notes:\n",
    "- QC Flags as defined by GHGSat:\n",
    "    - 1 = \"Good conditions\"\n",
    "    - 2 = \"Emissions detected and quantified, but suboptimal conditions may affect SR\" (what is SR?)\n",
    "    - 3 = \"Emissions detected, but not quantified due to suboptimal conditions\"\n",
    "    - 4 = \"Diffuse emissions visible over site (presumably from previous release, due to low wind)\"\n",
    "    - 5 = \"Discarded (Bad weather/conditions, including clouds, cloud shadow, highly irregular aircraft trajectory, etc.)\"\n",
    "- It looks like in some instances, GHGSat quantified plumes with QC Flag = 4, and in some places they did not. For now, I am not including any of QC-4 but will need to look into this more rigorously\n",
    "- QuantifiedPlume: compare QCFlags 1 and 2 for any significant difference in error estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m overpass \u001b[38;5;129;01min\u001b[39;00m gh_overpasses:\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Convert local time to UTC\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     local_time \u001b[38;5;241m=\u001b[39m ghg_1\u001b[38;5;241m.\u001b[39mloc[overpass\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp (hyperspectral technologies only)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     utc_time \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_utc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Determine if plume was quantified and set emission rate and uncertainty based on the reported QC flags by GHGSat\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ghg_1\u001b[38;5;241m.\u001b[39mloc[overpass\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQC Flag \u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/PycharmProjects/CRF22_Airplanes/data_methods.py:16\u001b[0m, in \u001b[0;36mconvert_utc\u001b[0;34m(dt, delta_t)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_utc\u001b[39m(dt, delta_t):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert input time (dt) to UTC. detla_t is the time difference between local time and UTC time. For Arizona,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    this value is + 7 hours\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     local_hr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m     local_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     18\u001b[0m     local_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "# GHGSat Data Cleaning\n",
    "\n",
    "# GHGSat conducted 192 overpasses\n",
    "total_overpass = 192\n",
    "# Set Stage for data analysis (1, 2 or 3)\n",
    "ghg_stage = 1\n",
    "\n",
    "# Code variables for iterating in the for loop\n",
    "gh_overpasses = np.linspace(1, total_overpass, total_overpass) # for indexing for loop\n",
    "overpass_list = [] # for generating all new rows\n",
    "\n",
    "for overpass in gh_overpasses:\n",
    "\n",
    "    # Convert local time to UTC\n",
    "    local_time = ghg_1.loc[overpass-1, \"Timestamp (hyperspectral technologies only)\"]\n",
    "    utc_time = convert_utc(local_time, 7)\n",
    "\n",
    "    # Determine if plume was quantified and set emission rate and uncertainty based on the reported QC flags by GHGSat\n",
    "    if ghg_1.loc[overpass-1, \"QC Flag \"] == 1 or 2:\n",
    "        quantified = 1\n",
    "        emission_rate = ghg_1.loc[overpass-1, \"Emission Rate (kg/hr)\"]\n",
    "        emission_upper = ghg_1.loc[overpass-1, \"FacilityEmissionRateUpper\"]\n",
    "        emission_lower = ghg_1.loc[overpass-1, \"FacilityEmissionRateLower\"]\n",
    "    else:\n",
    "        quantified = 0\n",
    "        emission_rate = float(\"nan\")\n",
    "        emission_upper = float(\"nan\")\n",
    "        emission_lower = float(\"nan\")\n",
    "\n",
    "    # Set QC flag:\n",
    "    ghg_flag = ghg_1.loc[overpass-1, \"QC Flag\"]\n",
    "    qc_flag = f'GH-{ghg_flag:1.0f}'\n",
    "\n",
    "\n",
    "    new_row = {\n",
    "            'Operator': 'GHGSat-AV',\n",
    "            'Stage': ghg_stage,\n",
    "            'PerformerExperimentID': f'GH-{overpass:1.0f}',\n",
    "            'DateOfSurvey': ghg_1.loc[overpass-1, \"DateOfSurvey\"].strftime('%Y-%m-%d'),\n",
    "            'TimestampUTC': utc_time,\n",
    "            'QuantifiedPlume': quantified,\n",
    "            'FacilityEmissionRate': emission_rate,\n",
    "            'FacilityEmissionRateUpper': emission_upper,\n",
    "            'FacilityEmissionRateLower': emission_lower,\n",
    "            'UncertaintyType': '1-sigma',\n",
    "            'OperatorWindspeed': ghg_1.loc[overpass-1, \"WindSpeed (m/s)\"],\n",
    "            'QCFlag': qc_flag,\n",
    "    }\n",
    "    overpass_list.append(new_row)\n",
    "\n",
    "ghg_clean = pd.DataFrame(overpass_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:45 PM\n",
      "13:45:00\n",
      "13:45:00\n",
      "1900-01-01 13:45:00\n",
      "13:45:00\n",
      "initial input to function is: 1:45 PM\n",
      "1900-01-01 13:45:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from data_methods import convert_to_twentyfour\n",
    "\n",
    "datetime_str = ghg_1.loc[63, \"Timestamp (hyperspectral technologies only)\"]\n",
    "print(datetime_str)\n",
    "gh_test = str(datetime.strptime(datetime_str, '%I:%M %p'))\n",
    "gh_time_only = gh_test[-8:]\n",
    "print(gh_time_only)\n",
    "gh_time_only = datetime.strptime(gh_time_only, '%H:%M:%S').time()\n",
    "print(gh_time_only)\n",
    "\n",
    "print(gh_test)\n",
    "print(gh_test[-8:])\n",
    "\n",
    "print(f'initial input to function is: {datetime_str}')\n",
    "test = convert_to_twentyfour(datetime_str)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metering data\n",
    "\n",
    "### Data description\n",
    "- Data uploaded on 2023-02-22 was generated by Philippine Burdeau on the same date. Sahar manually added a column for \"PerformerExperimentID\" and checked that the final number matched the \"PerformerExperimentID\" in the operator reports.\n",
    "- PerformerExperimentID:\n",
    "    - Kairos: 1 - 349, incrementing by 1 with each overpass\n",
    "    - GHGSat: First digits are the date, month, time (apparently in UTC), followed by info on line number and frame number, then incrementally increasing numbers from 1 - 192\n",
    "    - Carbon Mapper: 1 - 121, incrementing by 1 with each overpass\n",
    "- Timestamps match those reported by the operators\n",
    "\n",
    "\n",
    "### To do:\n",
    "- Compare all operator timestamps to our timestamps and to Flight Radar\n",
    "- Ultimately, use either our timestamp or FlightRadar for the definitive time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
